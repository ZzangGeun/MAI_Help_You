# LlamaIndex â†’ LangChain ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

## ğŸš€ ê°œìš”

MAI í”„ë¡œì íŠ¸ì˜ RAG ì‹œìŠ¤í…œì„ LlamaIndexì—ì„œ LangChainìœ¼ë¡œ ì™„ì „íˆ ì „í™˜í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ê¸°ëŠ¥ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ LangChainì˜ ê°•ë ¥í•œ ê¸°ëŠ¥ë“¤ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ”„ ì£¼ìš” ë³€ê²½ì‚¬í•­

### **1. íŒ¨í‚¤ì§€ ë³€ê²½**
```bash
# ì´ì „ (LlamaIndex)
llama-index>=0.10.0
llama-index-vector-stores-postgres>=0.2.0
llama-index-embeddings-huggingface>=0.2.0

# í˜„ì¬ (LangChain)
langchain>=0.1.0
langchain-community>=0.0.10
langchain-postgres>=0.0.6
sentence-transformers>=2.2.2
```

### **2. ì½”ë“œ êµ¬ì¡° ë³€ê²½**

#### **ì„ë² ë”© ëª¨ë¸**
```python
# ì´ì „ (LlamaIndex)
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
embed_model = HuggingFaceEmbedding(model_name="sentence-transformers/all-MiniLM-L6-v2")

# í˜„ì¬ (LangChain)
from langchain_community.embeddings import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    model_kwargs={'device': 'cpu'}
)
```

#### **ë²¡í„° ìŠ¤í† ì–´**
```python
# ì´ì „ (LlamaIndex)
from llama_index.vector_stores.postgres import PGVectorStore
vector_store = PGVectorStore.from_params(
    database=db, host=host, password=password,
    port=port, user=user, table_name=table_name,
    embed_dim=embed_dim
)

# í˜„ì¬ (LangChain)
from langchain_postgres.vectorstores import PGVector
vector_store = PGVector(
    collection_name=collection_name,
    connection_string=connection_string,
    embedding_function=embeddings
)
```

#### **ë¬¸ì„œ ì²˜ë¦¬**
```python
# ì´ì „ (LlamaIndex)
from llama_index.core import Document
documents = [Document(text=text, metadata={"file": fn})]

# í˜„ì¬ (LangChain)
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200
)
doc = Document(page_content=text, metadata={"source": fn})
split_docs = text_splitter.split_documents([doc])
```

## ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤

### **1. ê°œì„ ëœ ë¬¸ì„œ ì²­í‚¹**
```python
# ìë™ ë¬¸ì„œ ë¶„í• ë¡œ ë” ì •í™•í•œ ê²€ìƒ‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,        # ì²­í¬ í¬ê¸°
    chunk_overlap=200,      # ê²¹ì¹˜ëŠ” ë¶€ë¶„
    length_function=len,    # ê¸¸ì´ ê³„ì‚° í•¨ìˆ˜
)
```

### **2. ìœ ì‚¬ë„ ì ìˆ˜ ì œê³µ**
```python
# ê²€ìƒ‰ ê²°ê³¼ì— ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨
docs_with_scores = vector_store.similarity_search_with_score(query, k=3)
for doc, score in docs_with_scores:
    print(f"ìœ ì‚¬ë„: {score}, ë‚´ìš©: {doc.page_content}")
```

### **3. JSON ë°ì´í„° ì§€ëŠ¥í˜• íŒŒì‹±**
```python
def _json_to_text(self, json_obj: Dict[str, Any]) -> str:
    """JSONì„ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    text_parts = []
    for key, value in json_obj.items():
        if isinstance(value, (dict, list)):
            text_parts.append(f"{key}: {json.dumps(value, ensure_ascii=False, indent=2)}")
        else:
            text_parts.append(f"{key}: {value}")
    return "\n".join(text_parts)
```

### **4. ìœ ì—°í•œ ë¬¸ì„œ ê´€ë¦¬**
```python
# ìƒˆë¡œìš´ ë¬¸ì„œ ì¶”ê°€
rag_engine.add_documents([document1, document2])

# ëª¨ë“  ë¬¸ì„œ ì‚­ì œ (ì£¼ì˜!)
rag_engine.clear_documents()
```

## ğŸ”§ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ˆì°¨

### **1. íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸**
```bash
pip install -r requirements.txt
```

### **2. ê¸°ì¡´ ë°ì´í„° ì •ë¦¬ (ì„ íƒì‚¬í•­)**
```sql
-- ê¸°ì¡´ LlamaIndex í…Œì´ë¸” ì‚­ì œ (ì„ íƒì‚¬í•­)
DROP TABLE IF EXISTS your_old_table;
```

### **3. ì„œë²„ ì¬ì‹œì‘**
```bash
python manage.py runserver
```

### **4. ìë™ ì¬ì¸ë±ì‹±**
- ì²« ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ìƒˆë¡œìš´ LangChain í˜•ì‹ìœ¼ë¡œ ì¬ì¸ë±ì‹± ë©ë‹ˆë‹¤
- PostgreSQLì— ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„±: `langchain_pg_embedding_[collection_name]`

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| í•­ëª© | LlamaIndex | LangChain | ê°œì„ ì  |
|------|------------|-----------|--------|
| ë¬¸ì„œ ì²­í‚¹ | ë‹¨ìˆœ ë¶„í•  | ì§€ëŠ¥í˜• ë¶„í•  | ë” ì˜ë¯¸ìˆëŠ” ì²­í¬ |
| ê²€ìƒ‰ ì •í™•ë„ | ê¸°ë³¸ | ìœ ì‚¬ë„ ì ìˆ˜ | ê²°ê³¼ ì‹ ë¢°ì„± í–¥ìƒ |
| JSON ì²˜ë¦¬ | ì›ë³¸ í…ìŠ¤íŠ¸ | êµ¬ì¡°í™” íŒŒì‹± | ë” ë‚˜ì€ ì´í•´ë„ |
| í™•ì¥ì„± | ì œí•œì  | ë†’ìŒ | ë‹¤ì–‘í•œ ì²´ì¸ í™œìš© |

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### **1. ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½**
- LangChainì€ ë‹¤ë¥¸ í…Œì´ë¸” êµ¬ì¡°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤
- ê¸°ì¡´ ë°ì´í„°ëŠ” ìë™ìœ¼ë¡œ ì¬ì¸ë±ì‹±ë©ë‹ˆë‹¤

### **2. API í˜¸í™˜ì„±**
- `retrieve_texts()` ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€
- ì‘ë‹µì— `similarity_score` ì¶”ê°€ë¨

### **3. ë©”íƒ€ë°ì´í„° ë³€ê²½**
```python
# ì´ì „
{"file": "filename.json"}

# í˜„ì¬  
{
    "source": "filename.json",
    "file_path": "/full/path/filename.json",
    "file_type": "json",
    "similarity_score": 0.85
}
```

## ğŸ” ë¬¸ì œ í•´ê²°

### **ë¬¸ì œ 1: "langchain_postgres ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤"**
```bash
pip install langchain-postgres>=0.0.6
```

### **ë¬¸ì œ 2: ê¸°ì¡´ ë°ì´í„°ê°€ ê²€ìƒ‰ë˜ì§€ ì•ŠìŒ**
- ì²« ì‹¤í–‰ ì‹œ ì¬ì¸ë±ì‹±ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”
- ë¡œê·¸ì—ì„œ "ì¸ë±ì‹± ì™„ë£Œ" ë©”ì‹œì§€ í™•ì¸

### **ë¬¸ì œ 3: PostgreSQL ì—°ê²° ì˜¤ë¥˜**
```python
# ì—°ê²° ë¬¸ìì—´ í˜•ì‹ í™•ì¸
connection_string = "postgresql+psycopg2://user:pass@host:port/db"
```

## âœ… ê²€ì¦ ë°©ë²•

### **1. RAG ì—”ì§„ í…ŒìŠ¤íŠ¸**
```python
# Django shellì—ì„œ
from apps.chatbot.rag_engine import RagEngine

rag = RagEngine()
results = rag.retrieve_texts("ë©”ì´í”ŒìŠ¤í† ë¦¬ ë ˆë²¨ì—…")
print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
for text, metadata in results:
    print(f"ì ìˆ˜: {metadata.get('similarity_score', 'N/A')}")
```

### **2. API í…ŒìŠ¤íŠ¸**
```bash
# DRF API í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/api/v1/chatbot/ask/ \
  -H "Content-Type: application/json" \
  -d '{"question": "ë©”ì´í”ŒìŠ¤í† ë¦¬ ì§ˆë¬¸"}'
```

### **3. ë¬¸ì„œ ê°œìˆ˜ í™•ì¸**
```sql
-- ìƒˆë¡œìš´ í…Œì´ë¸”ì—ì„œ ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
SELECT COUNT(*) FROM langchain_pg_embedding_[your_collection_name];
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### **1. LangChain ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©**
- **ì²´ì¸ êµ¬ì„±**: ë‹¤ë‹¨ê³„ ì¶”ë¡  ì²´ì¸
- **ì—ì´ì „íŠ¸**: ë™ì  ë„êµ¬ ì‚¬ìš©
- **ë©”ëª¨ë¦¬**: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

### **2. ì„±ëŠ¥ ìµœì í™”**
```python
# ìºì‹± í™œìš©
from langchain.cache import InMemoryCache
llm.cache = InMemoryCache()

# ë°°ì¹˜ ì²˜ë¦¬
vector_store.add_documents(documents, batch_size=100)
```

### **3. ëª¨ë‹ˆí„°ë§**
```python
# ì„±ëŠ¥ ë¡œê¹…
import time
start_time = time.time()
results = rag.retrieve_texts(query)
logger.info(f"ê²€ìƒ‰ ì‹œê°„: {time.time() - start_time:.3f}ì´ˆ")
```

## ğŸ“š ì°¸ê³  ìë£Œ

- **LangChain ê³µì‹ ë¬¸ì„œ**: https://docs.langchain.com/
- **PGVector ì„¤ì •**: https://github.com/pgvector/pgvector
- **ì„ë² ë”© ëª¨ë¸**: https://huggingface.co/sentence-transformers

---

LlamaIndexì—ì„œ LangChainìœ¼ë¡œì˜ ì „í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰  
ë” ê°•ë ¥í•˜ê³  ìœ ì—°í•œ RAG ì‹œìŠ¤í…œì„ í™œìš©í•´ë³´ì„¸ìš”.
